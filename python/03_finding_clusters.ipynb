{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a730e2d-7e75-4157-90d9-b0569888017a",
   "metadata": {},
   "source": [
    "# Finding clusters in data generated by the HIV branching process simulator\n",
    "\n",
    "This notebook shows how to compute clusters using the code at [https://github.com/ghart-IDM/HIVclusteringExample/blob/clustering/fall2022Review/getClusters.py](https://github.com/ghart-IDM/HIVclusteringExample/blob/clustering/fall2022Review/getClusters.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0d5808-3d58-4680-89d2-0fa83a9a1d7b",
   "metadata": {},
   "source": [
    "Let's start by loading the requierd packages, including IDM's phylomodels as well as the branching process simulator that is coded in R:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88c8695e-3f11-4505-9954-adf14028c8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# IDM's phylomodels\n",
    "from phylomodels.trees import generate_treeFromFile\n",
    "from phylomodels.trees.transform_transToPhyloTree import transform_transToPhyloTree\n",
    "from phylomodels.trees.transform_joinTrees import transform_joinTrees\n",
    "\n",
    "# R-related packages\n",
    "import rpy2\n",
    "import rpy2.robjects as robjects\n",
    "r = robjects.r\n",
    "\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "\n",
    "# We may need to install some packages\n",
    "try:\n",
    "    from rpy2.robjects.packages import importr\n",
    "    dplyr = importr('dplyr')\n",
    "except RRuntimeError:\n",
    "    from rpy2.robjects.packages import importr, data\n",
    "    utils = importr('utils')\n",
    "    base = importr('base')\n",
    "    utils.chooseCRANmirror()\n",
    "    utils.install_packages('dplyr')\n",
    "\n",
    "# Set up working directory\n",
    "cwd = os.getcwd()\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5e6cd1-0b7a-42f8-904d-da93b0f4517d",
   "metadata": {},
   "source": [
    "Now let's run a simulation and clean up its output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77e57ab2-eeb9-4d4b-b4d1-48b697a2657f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <span>ListVector with 2 elements.</span>\n",
       "        <table>\n",
       "        <tbody>\n",
       "        \n",
       "          <tr>\n",
       "            <th>\n",
       "            value\n",
       "            </th>\n",
       "            <td>\n",
       "            <rpy2.rinterface_lib.sexp.NULLType object at 0x7f0148771dc0> [RTYPES.NILSXP]\n",
       "            </td>\n",
       "          </tr>\n",
       "        \n",
       "          <tr>\n",
       "            <th>\n",
       "            visible\n",
       "            </th>\n",
       "            <td>\n",
       "            <rpy2.rinterface.BoolSexpVector object at 0x7f019c50fc80> [RTYPES.LGLSXP]\n",
       "            </td>\n",
       "          </tr>\n",
       "        \n",
       "        </tbody>\n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "<rpy2.robjects.vectors.ListVector object at 0x7f019c4d0d80> [RTYPES.VECSXP]\n",
       "R classes: ('list',)\n",
       "[NULLType, BoolSexpVector]\n",
       "  value: <class 'rpy2.rinterface_lib.sexp.NULLType'>\n",
       "  <rpy2.rinterface_lib.sexp.NULLType object at 0x7f0148771dc0> [RTYPES.NILSXP]\n",
       "  visible: <class 'rpy2.rinterface.BoolSexpVector'>\n",
       "  <rpy2.rinterface.BoolSexpVector object at 0x7f01374d1800> [RTYPES.LGLSXP]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.source('hiv_branching_process.R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08989b01-1db1-4b46-83bd-470b8e512e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |==================================================| 100%\n"
     ]
    }
   ],
   "source": [
    "out = r.simulate_transmission( sim_time=365*10 )\n",
    "population_summary_r  = out.rx2('population_summary' )\n",
    "transmission_record_r = out.rx2('transmission_record')\n",
    "\n",
    "with localconverter( robjects.default_converter + pandas2ri.converter ):\n",
    "    population_summary  = robjects.conversion.rpy2py( population_summary_r  )\n",
    "    transmission_record = robjects.conversion.rpy2py( transmission_record_r )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "566cd266-269d-487a-b6ed-35783071cdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "population_summary['recipient'] = population_summary['recipient'].astype(int).astype(str)\n",
    "population_summary['source'] = population_summary['source'].astype(int).astype(str)\n",
    "\n",
    "# Let's get rid of seed infections that didn't produce other infections\n",
    "all_seeds = population_summary[ population_summary['source']=='0' ].index\n",
    "all_infected_by_seed = population_summary[ population_summary['source'].isin( all_seeds ) ]\n",
    "all_successful_seeds = all_infected_by_seed['source'].unique()\n",
    "all_unsuccessful_seeds = list( set(all_seeds) - set(all_successful_seeds) )\n",
    "population_summary_lean = population_summary.drop( index=all_unsuccessful_seeds )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa8c5f6-f040-46ea-bd90-77f8ff33f961",
   "metadata": {},
   "source": [
    "We can build the transmission tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d630cacb-8143-44a8-8f10-500879950d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of leaf nodes:\t4260\n",
      "Total number of nodes:\t8519\n",
      "Rooted:\tYes\n",
      "Most distant node:\t4012\n",
      "Max. distance:\t4351.307646\n"
     ]
    }
   ],
   "source": [
    "trees = generate_treeFromFile.read_treeFromLineList( population_summary,\n",
    "                                                     ID = 'recipient',\n",
    "                                                     infectorID = 'source',\n",
    "                                                     infectTime = 'infectionTime',\n",
    "                                                     sampleTime = 'sampleTime',\n",
    "                                                     features = ['partners', 'acts_per_day', 'transmission_risk_per_act', 'removal_rate']\n",
    "                                                   )\n",
    "raw_tree = trees[0]\n",
    "\n",
    "seeds = raw_tree.get_children()\n",
    "seeds_phylo = []\n",
    "for this_seed in seeds:\n",
    "    seed_tree = transform_transToPhyloTree( this_seed )\n",
    "    seeds_phylo.append( seed_tree )\n",
    "\n",
    "tree = transform_joinTrees( seeds_phylo )\n",
    "tree.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fce1eb4-6e41-4e2d-bfe0-45db7777d1f7",
   "metadata": {},
   "source": [
    "And finally, let's compute clustering metrics.\n",
    "\n",
    "First, let's code some utility functions (copied from [https://github.com/ghart-IDM/HIVclusteringExample/blob/clustering/fall2022Review/getClusters.py](https://github.com/ghart-IDM/HIVclusteringExample/blob/clustering/fall2022Review/getClusters.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21c8671f-fc87-42fe-be26-94a055af5d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_up (nodes, curnode, pathlen, topology_only=False):\n",
    "    \"\"\"\n",
    "    Recursive function for traversing up a tree.\n",
    "    \"\"\"\n",
    "    if topology_only:\n",
    "        pathlen += 1\n",
    "        if curnode.is_leaf():\n",
    "            nodes.append( (curnode.name, pathlen) )\n",
    "        else:\n",
    "            nodes.append( (curnode.name, pathlen) )\n",
    "            for c in curnode.children:\n",
    "                nodes = walk_up(nodes, c, pathlen, topology_only)\n",
    "    else:\n",
    "        pathlen += curnode.dist\n",
    "        if curnode.is_leaf():\n",
    "            nodes.append( (curnode.name, pathlen) )\n",
    "        else:\n",
    "            nodes.append( (curnode.name, pathlen) )\n",
    "            for c in curnode.children:\n",
    "                nodes = walk_up(nodes, c, pathlen, topology_only)\n",
    "\n",
    "    return nodes\n",
    "\n",
    "\n",
    "def find_short_edges(tree, topology_only=False):\n",
    "    \"\"\"\n",
    "    Find the shortest edge from the earliest sequence of a patient to a\n",
    "    any sequence from any other patient.\n",
    "    minimize = keep only edge from earliest seq to the closest other seq\n",
    "    keep_ties = [to be used in conjunction with minimize]\n",
    "                report all edges with the same minimum distance\n",
    "    \"\"\"\n",
    "\n",
    "    # generate dictionary of child->parent associations\n",
    "    parents = {}\n",
    "    names = []\n",
    "    for clade in tree.traverse('levelorder'):\n",
    "        names.append(clade.name)\n",
    "        for child in clade.children:\n",
    "            parents.update({child: clade})\n",
    "\n",
    "    nodes = tree.get_descendants('levelorder')\n",
    "    num_nodes = len(nodes)\n",
    "    distance = np.zeros((num_nodes+1, num_nodes+1), dtype=np.float32)\n",
    "    index = {tree.name: 0}\n",
    "    count = 1\n",
    "    for node in nodes:\n",
    "        index.update({node.name: count})\n",
    "        count += 1\n",
    "        \n",
    "    # Get distances from root\n",
    "    node2 = walk_up([], tree, {True: -1, False: -tree.dist}[topology_only], topology_only)\n",
    "    \n",
    "    i = index[tree.name]\n",
    "    for n2, dist in node2:\n",
    "        j = index[n2]\n",
    "        distance[i, j] = dist\n",
    "    distance[i, i] = 0\n",
    "    \n",
    "    for node in nodes:\n",
    "        i = index[node.name]\n",
    "        j = index[parents[node].name]\n",
    "        dist = {True: 1, False: node.dist}[topology_only]\n",
    "        distance[i, :] = distance[j, :] + dist\n",
    "        node2 = walk_up([], node, {True: -1, False: -node.dist}[topology_only], topology_only)\n",
    "        \n",
    "        \n",
    "        for n2, dist in node2:\n",
    "            j = index[n2]\n",
    "            distance[i, j] = dist\n",
    "        distance[i, i] = 0\n",
    "            \n",
    "    return distance, names\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdce2db8-9c81-4e3d-a2a7-167cb877c631",
   "metadata": {},
   "source": [
    "The clustering metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc7f3628-b717-4788-94ac-4cb6ae4771a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8519 number of nodes\n",
      "4260 number of leaves\n",
      "16 clusters of average size 2.31 for cutoff 50.0\n",
      "21 clusters of average size 2.62 for cutoff 100.0\n",
      "18 clusters of average size 3.56 for cutoff 200.0\n",
      "19 clusters of average size 3.58 for cutoff 300.0\n",
      "18 clusters of average size 3.94 for cutoff 400.0\n",
      "17 clusters of average size 4.53 for cutoff 500.0\n",
      "15 clusters of average size 6.00 for cutoff 600.0\n",
      "13 clusters of average size 9.69 for cutoff 700.0\n",
      "780 clusters of average size 4.87 for cutoff 800.0\n",
      "547 clusters of average size 7.38 for cutoff 900.0\n",
      "450 clusters of average size 9.19 for cutoff 1000.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse.csgraph import connected_components\n",
    "\n",
    "# Get nearest neighbor list\n",
    "distance, names = find_short_edges(tree)\n",
    "leaves = tree.get_leaf_names()\n",
    "names = np.array(names)\n",
    "print(len(names), 'number of nodes')\n",
    "print(len(leaves), 'number of leaves')\n",
    "idx = np.in1d(names, leaves)\n",
    "distance = distance[idx,:][:,idx]\n",
    "np.fill_diagonal(distance, float('inf'))\n",
    "names = names[idx]\n",
    "    \n",
    "# Calculate clusters\n",
    "cutoffs = np.multiply( 100, [0.5, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0] )\n",
    "for i, cutoff in enumerate(cutoffs):\n",
    "    num_clusters, cluster_labels = connected_components(distance < cutoff)\n",
    "    cluster_labels = cluster_labels.tolist()\n",
    "\n",
    "    cluster_sizes = { str(i): cluster_labels.count(i) for i in cluster_labels }\n",
    "    cluster_size_distribution = {}\n",
    "    for cluster_id, size in cluster_sizes.items():\n",
    "        if size != 1:  # we are interested in clusters, not singletons\n",
    "            cluster_size_distribution[str(size)] = 1 + cluster_size_distribution.get( str(size), 0 )\n",
    "    \n",
    "    n_clusters = 0\n",
    "    if len(cluster_size_distribution) != 0:\n",
    "        cluster_size_sum = 0\n",
    "        for key, value in cluster_size_distribution.items():\n",
    "            n_clusters += value\n",
    "            cluster_size_sum += int(key)*value\n",
    "        avg_cluster_size = ( cluster_size_sum/n_clusters )\n",
    "    else:\n",
    "        avg_cluster_size = 0\n",
    "\n",
    "    print( '{:2} clusters of average size {:.2f} for cutoff {}'.format(n_clusters, avg_cluster_size, cutoff) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (clustersim_20230720)",
   "language": "python",
   "name": "clustersim_20230720"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
